# -*- coding: utf-8 -*-
"""Section 11 Project Assignment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Z4UryzlZZMzGzAZVO2pZ8IcfYjGX-k-a

**Loading all necessary packages**
"""

from pyforest import*
from sklearn.utils import resample
from sklearn.metrics import classification_report
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.ensemble import AdaBoostClassifier

import warnings
warnings.filterwarnings('ignore')

"""## Loading the data, the first observation, and EDA"""

df=pd.read_csv('bank-full+(1).csv')

df.shape

df.head()

#The data type of each attribute
df.dtypes

#Checking the presence of missing values
df.isna().sum()

#Point summary of numerical attributes
df.describe().T

for i in df.describe().columns:
    sns.distplot(df[i]) #there is no na in the dataframe as it is clear from the previous lines, and so there is
    plt.show()                    #need to use .dropna

#Checking the presence of outliers
for i in df.describe().columns:
    sns.boxplot(df[i])
    plt.show()

"""## Prepare the data to train a model

### Categorical Features

**job**
"""

df.job.value_counts() #there is 'unknown' data that should be handled.

df['job'] = df['job'].replace({'unknown':'blue-collar'})

df.job.value_counts() #'unknown' replaced by the mode of the column ('blue-collar').

"""**marital**"""

df.marital.value_counts() #there is no 'unknown' data, so it is good to go.

"""**education**"""

df.education.value_counts() #there is 'unknown' data that should be handled.

df['education'] = df['education'].replace({'unknown':'secondary'})

df.education.value_counts() #'unknown' replaced by the mode of the column ('secondary').

"""**default**"""

df.default.value_counts() #there is no 'unknown' data, so it is good to go.

"""**housing**"""

df.housing.value_counts() #there is no 'unknown' data, so it is good to go.

"""**loan**"""

df.loan.value_counts() #there is no 'unknown' data, so it is good to go.

"""**contact**"""

df.contact.value_counts() #there is 'unknown' data that should be handled.

df['contact'] = df['contact'].replace({'unknown':'cellular'})

df.contact.value_counts() #'unknown' replaced by the mode of the column ('cellular').

"""**month**"""

df.month.value_counts() #there is no 'unknown' data, so it is good to go.

"""**poutcome**"""

df.poutcome.value_counts()

"""Beacuse most of the data in 'poutcome' column is unknown, it would not be a helpful data for the classification. Therefor I will drop it."""

df.drop(['poutcome'], axis=1, inplace=True)

df.head(1)

"""### Numerical Features"""

#As mentioned in the Data Description, the 'duration' column, would not be helpful. So, I'm droping it.
df.drop(['duration'], axis=1, inplace=True)

"""**pdays**"""

df.pdays.describe()

(df.pdays < 0).sum() #Nearly all the data in pdays column is -1 which is not a meaningful data. So I'm droping it.

df.drop(['pdays'], axis=1, inplace=True)

df.head(1)

df.boxplot(figsize=(16,10))

"""As it is clear from the above boxplot for numerical features there ar lots of outliers that should be handled. And also, the data should be normalized."""

# Handling Outliers

cols_of_interest = ['age', 'balance', 'campaign', 'previous']

for col in cols_of_interest:
    Q1=df[col].quantile(q=0.25)
    Q3=df[col].quantile(q=0.75)
    IQR=Q3-Q1
    L_outliers=Q1-1.5*(IQR)
    U_outliers=Q3+1.5*(IQR)
    df.loc[(df[col] < L_outliers) | (df[col] > U_outliers), col] = df[col].median()

df.boxplot(figsize=(16,10))

"""### Target column cheking for imbalancity."""

df['Target'].value_counts()

"""Clearly the data is imbalance. So it should be cared.

**Up Sampling**

Prior to upsampling the data should be divide into train and test. The class that should be upsampled is **'yes'**.
"""

X=df.drop('Target',axis=1)
y=df['Target']

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=1)

X=pd.concat([X_train,y_train],axis=1)
X.head()

subscribed=X[X['Target']=='yes']
not_subscribed=X[X['Target']=='no']

subscribed_upsampled=resample(subscribed,replace=True, n_samples=len(not_subscribed), random_state=1)

upsampled=pd.concat([not_subscribed, subscribed_upsampled])

upsampled['Target'].value_counts()

X_train=upsampled.drop('Target', axis=1)
y_train=upsampled['Target']

"""## Normalization"""

scaler=StandardScaler()

cols_to_normalize=['age', 'balance', 'campaign', 'previous']

train_numcols= X_train[cols_to_normalize]
train_numcols=pd.DataFrame(scaler.fit_transform(train_numcols))
train_numcols.columns = cols_to_normalize

X_train.drop(cols_to_normalize, axis=1, inplace=True)
X_train=X_train.reset_index()
X_train = pd.concat([X_train, train_numcols], axis=1)

X_train.drop(['index'],axis=1,inplace=True)
X_train.head()

test_numcols= X_test[cols_to_normalize]
test_numcols=pd.DataFrame(scaler.fit_transform(test_numcols))
test_numcols.columns = cols_to_normalize

X_test.drop(cols_to_normalize, axis=1, inplace=True)
X_test=X_test.reset_index()
X_test = pd.concat([X_test, test_numcols], axis=1)

X_test.drop(['index'],axis=1,inplace=True)
X_test.head()

"""## Handling Categorical Features"""

y_train=y_train.reset_index()
train = pd.concat([X_train, y_train], axis=1)

y_test=y_test.reset_index()
test = pd.concat([X_test, y_test], axis=1)

train['source']='train'
test['source']='test'
newdf=pd.concat([train, test], ignore_index=True)
newdf.drop(['index'], axis=1, inplace=True)

label=LabelEncoder()

cat_features=['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact','day', 'month']

for i in cat_features:
    newdf[i] = label.fit_transform(newdf[i])

newdf.head()

newdf=pd.get_dummies(newdf, columns=['job', 'marital', 'education', 'default', 
                               'housing', 'loan', 'contact','day', 'month'])

newdf.head()

train = newdf.loc[newdf['source'] == 'train']
test = newdf.loc[newdf['source'] == 'test']

train.drop(['source'], axis=1, inplace=True)
train.head()

test.drop(['source'], axis=1, inplace=True)
test.head()

X_train = train.drop(['Target'], axis=1)
X_test = test.drop(['Target'], axis=1)
y_train = train['Target']
y_test = test['Target']

"""## Model Building

### Logistic Regression
"""

LR=LogisticRegression(random_state=1)

LR.fit(X_train,y_train)

train_score=LR.score(X_train, y_train)
train_score

test_score=LR.score(X_test, y_test)
test_score

LR_pred=LR.predict(X_test)

cm=metrics.confusion_matrix(y_test,LR_pred,labels=['no','yes'])
cm

df_cm=pd.DataFrame(cm,index=[i for i in ['Real no','Real yes']],columns=[i for i in ['Predicted no', 'Predicted yes']])
df_cm

plt.figure(figsize=(7,5))
sns.heatmap(df_cm,annot=True,cmap='viridis');

print(classification_report(y_test, LR_pred))

results_LR = pd.DataFrame({'Algorithm': ['Logistic Regression'],'Model Score on Train':train_score, 
                           'Model Score on Test':test_score},index={'1'})
results = results_LR[['Algorithm','Model Score on Train','Model Score on Test']]
results

"""### SVM"""

svm=SVC()

svm.fit(X_train,y_train)

train_score=svm.score(X_train, y_train)
train_score

test_score=svm.score(X_test, y_test)
test_score

svm_pred=svm.predict(X_test)

cm=metrics.confusion_matrix(y_test,svm_pred,labels=['no','yes'])
cm

df_cm=pd.DataFrame(cm,index=[i for i in ['Real no','Real yes']],columns=[i for i in ['Predicted no', 'Predicted yes']])
df_cm

plt.figure(figsize=(7,5))
sns.heatmap(df_cm,annot=True,cmap='viridis');

print(classification_report(y_test, svm_pred))

result_svm = pd.DataFrame({'Algorithm': ['SVM'], 'Model Score on Train':train_score, 
                           'Model Score on Test':test_score},index={'2'})
results = pd.concat([results, result_svm])
results = results[['Algorithm','Model Score on Train','Model Score on Test']]
results

"""### Decission Tree"""

DT=DecisionTreeClassifier()

DT.fit(X_train, y_train)

train_score=DT.score(X_train, y_train)
train_score

test_score=DT.score(X_test, y_test)
test_score

DT_pred=DT.predict(X_test)

cm=metrics.confusion_matrix(y_test,DT_pred,labels=['no','yes'])
cm

df_cm=pd.DataFrame(cm,index=[i for i in ['Real no','Real yes']],columns=[i for i in ['Predicted no', 'Predicted yes']])
df_cm

plt.figure(figsize=(7,5))
sns.heatmap(df_cm,annot=True,cmap='viridis');

print(classification_report(y_test, DT_pred))

result_DT = pd.DataFrame({'Algorithm': ['Decision Tree'], 'Model Score on Train':train_score, 
                           'Model Score on Test':test_score},index={'3'})
results = pd.concat([results, result_DT])
results = results[['Algorithm','Model Score on Train','Model Score on Test']]
results

"""### KNN"""

k=[1,3,5,7,9,11,13,15]
test=[]
train=[]
for i in k:
  knn=KNeighborsClassifier(n_neighbors=i)
  knn.fit(X_train,y_train)
  train.append(knn.score(X_train,y_train))
  test.append(knn.score(X_test,y_test))

plt.figure(figsize=(12,6))
plt.plot(k,train,color='blue',linestyle='dashed',marker='o',markerfacecolor='red',markersize=10)
plt.plot(k,test,color='red',linestyle='dashed',marker='o',markerfacecolor='blue',markersize=10)
plt.title('Different K Values')
plt.xlabel('K Values')
plt.ylabel('Score')

knn=KNeighborsClassifier(n_neighbors=15)

knn.fit(X_train, y_train)

train_score=knn.score(X_train, y_train)
train_score

test_score=knn.score(X_test, y_test)
test_score

knn_pred=knn.predict(X_test)

cm=metrics.confusion_matrix(y_test,knn_pred,labels=['no','yes'])

df_cm=pd.DataFrame(cm,index=[i for i in ['Real no','Real yes']],columns=[i for i in ['Predicted no', 'Predicted yes']])
df_cm

plt.figure(figsize=(7,5))
sns.heatmap(df_cm,annot=True,cmap='viridis');

print(classification_report(y_test, knn_pred))

result_knn = pd.DataFrame({'Algorithm': ['KNN'], 'Model Score on Train':train_score, 
                           'Model Score on Test':test_score},index={'4'})
results = pd.concat([results, result_knn])
results = results[['Algorithm','Model Score on Train','Model Score on Test']]
results

"""### Random Forest"""

rfc=RandomForestClassifier(n_estimators=50,criterion='entropy',random_state=1)

rfc.fit(X_train,y_train)

train_score=rfc.score(X_train, y_train)
train_score

test_score=rfc.score(X_test, y_test)
test_score

rfc_pred=rfc.predict(X_test)

cm=metrics.confusion_matrix(y_test,rfc_pred,labels=['no','yes'])
cm

df_cm=pd.DataFrame(cm,index=[i for i in ['Real no','Real yes']],columns=[i for i in ['Predicted no', 'Predicted yes']])
df_cm

plt.figure(figsize=(7,5))
sns.heatmap(df_cm,annot=True,cmap='viridis');

print(classification_report(y_test, rfc_pred))

result_rfc = pd.DataFrame({'Algorithm': ['Random Forest'], 'Model Score on Train':train_score, 
                           'Model Score on Test':test_score},index={'5'})
results = pd.concat([results, result_rfc])
results = results[['Algorithm','Model Score on Train','Model Score on Test']]
results

"""### Gradiant Boost"""

GB=GradientBoostingClassifier()

GB.fit(X_train,y_train)

train_score=GB.score(X_train, y_train)
train_score

test_score=GB.score(X_test, y_test)
test_score

GB_pred=GB.predict(X_test)

cm=metrics.confusion_matrix(y_test,GB_pred,labels=['no','yes'])

df_cm=pd.DataFrame(cm,index=[i for i in ['Real no','Real yes']],columns=[i for i in ['Predicted no', 'Predicted yes']])
df_cm

plt.figure(figsize=(7,5))
sns.heatmap(df_cm,annot=True,cmap='viridis');

print(classification_report(y_test, GB_pred))

result_GB = pd.DataFrame({'Algorithm': ['Gradiant Boost'], 'Model Score on Train':train_score, 
                           'Model Score on Test':test_score},index={'6'})
results = pd.concat([results, result_GB])
results = results[['Algorithm','Model Score on Train','Model Score on Test']]
results

"""### Ada Boost"""

AB=AdaBoostClassifier()

AB.fit(X_train,y_train)

train_score=AB.score(X_train, y_train)
train_score

test_score=AB.score(X_test, y_test)
test_score

AB_pred=AB.predict(X_test)

cm=metrics.confusion_matrix(y_test,AB_pred,labels=['no','yes'])

df_cm=pd.DataFrame(cm,index=[i for i in ['Real no','Real yes']],columns=[i for i in ['Predicted no', 'Predicted yes']])
df_cm

plt.figure(figsize=(7,5))
sns.heatmap(df_cm,annot=True,cmap='viridis');

print(classification_report(y_test, AB_pred))

result_AB = pd.DataFrame({'Algorithm': ['Ada Boost'], 'Model Score on Train':train_score, 
                           'Model Score on Test':test_score},index={'7'})
results = pd.concat([results, result_AB])
results = results[['Algorithm','Model Score on Train','Model Score on Test']]
results

"""## Comparing All Models"""

data = results.melt('Algorithm', var_name='Train/Test', value_name='Score')
data

plt.figure(figsize=(20, 8))
sns.catplot(x="Algorithm", y="Score", hue="Train/Test", kind="bar", data=data)
plt.xticks(rotation=75)

"""As it is clear from the above bar plot Ensemble models are generaly more resistance against **over fitting** than base models.
KNN has the most over fitting. I believe that it is beacuse of the fact that I did not find the best neighbor number for this model. 
Both Decision Tree and Random forest are equal in model score on train data, but Random Forest is bit better in model score on test data, which can be translate to less overfitting, which is the power of ensemble methods.  
"""